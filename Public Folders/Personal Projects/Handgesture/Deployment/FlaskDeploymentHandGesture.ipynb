{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "RM5Jw6z_UL3p"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-09 08:51:21.695517: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, render_template, request\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import io\n",
    "import base64\n",
    "from tensorflow.keras.models import load_model\n",
    "from pyngrok import ngrok, conf\n",
    "import getpass\n",
    "import threading\n",
    "from flasgger import Swagger\n",
    "from flask_cors import CORS\n",
    "from datetime import datetime\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "-UE4bxXsaA7u"
   },
   "outputs": [],
   "source": [
    "code_path = '/Volumes/Datasets/HandGesture/models'\n",
    "model = load_model(os.path.join(code_path,'HagridModel1.keras'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * ngrok tunnel \"https://24ad-2600-4041-7ad1-3200-255b-10cf-72e8-d1b0.ngrok-free.app\" -> \"http://127.0.0.1:5001\"\n",
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:5001\n",
      " * Running on http://192.168.1.176:5001\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [09/Apr/2025 08:51:26] \"GET /socket.io/?EIO=4&transport=polling&t=POQclbL HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [09/Apr/2025 08:51:32] \"GET /socket.io/?EIO=4&transport=polling&t=POQcn35 HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [09/Apr/2025 08:51:38] \"GET /socket.io/?EIO=4&transport=polling&t=POQcoWr HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [09/Apr/2025 08:51:41] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [09/Apr/2025 08:51:41] \"GET /static/styles.css HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [09/Apr/2025 08:51:41] \"GET /favicon.ico HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [09/Apr/2025 08:51:44] \"GET /socket.io/?EIO=4&transport=polling&t=POQcp-c HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [09/Apr/2025 08:51:50] \"GET /socket.io/?EIO=4&transport=polling&t=POQcrSL HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [09/Apr/2025 08:51:56] \"GET /socket.io/?EIO=4&transport=polling&t=POQcsw5 HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [09/Apr/2025 08:52:02] \"GET /socket.io/?EIO=4&transport=polling&t=POQcuNs HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [09/Apr/2025 08:52:08] \"GET /socket.io/?EIO=4&transport=polling&t=POQcvrb HTTP/1.1\" 404 -\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"FLASK_DEBUG\"] = \"development\"\n",
    "\n",
    "app = Flask(__name__)\n",
    "swagger = Swagger(app)\n",
    "CORS(app)\n",
    "port = 5001\n",
    "\n",
    "\n",
    "# Open a ngrok tunnel to the HTTP server\n",
    "public_url = ngrok.connect(port, bind_tls=True).public_url\n",
    "print(f\" * ngrok tunnel \\\"{public_url}\\\" -> \\\"http://127.0.0.1:{port}\\\"\")\n",
    "\n",
    "\n",
    "# Update any base URLs to use the public ngrok URL\n",
    "app.config[\"BASE_URL\"] = public_url\n",
    "\n",
    "# Preprocessing function for live image input (adjust as per your model)\n",
    "def preprocess_image(img):\n",
    "    # Decode the image into a tensor\n",
    "    img = tf.convert_to_tensor(img, dtype=tf.float32)\n",
    "    img_resized = tf.image.resize(img, [224, 224])\n",
    "    # Preprocess the image using MobileNet's preprocessing function\n",
    "    img_preprocessed = tf.keras.applications.mobilenet.preprocess_input(img_resized)\n",
    "    # Add a batch dimension\n",
    "    img_batch = tf.expand_dims(img_preprocessed, axis=0)\n",
    "\n",
    "    return img_batch, img_resized\n",
    "\n",
    "\n",
    "\n",
    "def predict_model(img_batch, img_resized):\n",
    "    # Perform the prediction\n",
    "    prediction = model.predict(img_batch)\n",
    "\n",
    "    buffer = io.BytesIO()\n",
    "    plt.imshow(tf.cast(img_resized, tf.uint8))\n",
    "\n",
    "    labels = ['Dislike', 'Like', 'Mute', 'OK', 'Stop']\n",
    "    plt.title(labels[prediction.argmax()])\n",
    "    plt.axis('off')\n",
    "    plt.savefig(buffer, format='png')\n",
    "    plt.close()\n",
    "    #Encode the image to base64 string\n",
    "    buffer.seek(0)\n",
    "    image_string = base64.b64encode(buffer.read()).decode('utf-8')\n",
    "\n",
    "    return labels[prediction.argmax()], image_string\n",
    "\n",
    "\n",
    "# Define the prediction route\n",
    "@app.route('/', methods=['GET', 'POST'])\n",
    "def predict():\n",
    "\n",
    "    chart_url = None\n",
    "    if request.method == 'POST':\n",
    "\n",
    "        # Get the image from the request\n",
    "        file = request.files['file']\n",
    "        # Read the image for processing without saving it first\n",
    "        img = cv2.imdecode(np.frombuffer(file.read(), np.uint8), cv2.IMREAD_COLOR)\n",
    "\n",
    "        # Preprocess the image\n",
    "        img_batch, img_resized = preprocess_image(img)\n",
    "        \n",
    "        # Get the prediction name and the prediction image\n",
    "        prediction_name, img_prediction = predict_model(img_batch, img_resized)\n",
    "\n",
    "        # Construct the filename using the prediction name\n",
    "        filename = f\"Upload_{prediction_name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.jpg\"\n",
    "        path = '/Volumes/Datasets/SavedImages/'\n",
    "        save_path = os.path.join(path, filename)\n",
    "\n",
    "        # Save the image with the prediction name\n",
    "        cv2.imwrite(save_path, img)\n",
    "\n",
    "        # Prepare the data for displaying in HTML (data:image/png;base64, ...)\n",
    "        chart_url = f\"{img_prediction}\"\n",
    "\n",
    "    return render_template('handgestureIndex.html', chart_url =chart_url) #,int(predicted_class[0])\n",
    "\n",
    "\n",
    "# Define the capture route for webcam images\n",
    "@app.route('/capture', methods=['POST'])\n",
    "def capture():\n",
    "    data = request.form['image_base64']\n",
    "\n",
    "    # Decode the base64 image\n",
    "    image_data = data.split(',')[1]  # Strip the data:image/jpeg;base64, header\n",
    "    decoded_image = base64.b64decode(image_data)\n",
    "\n",
    "    # Convert to NumPy array and decode\n",
    "    npimg = np.frombuffer(decoded_image, np.uint8)\n",
    "    img = cv2.imdecode(npimg, cv2.IMREAD_COLOR)\n",
    "    \n",
    "\n",
    "    # Preprocess the image\n",
    "    img_batch, img_resized = preprocess_image(img)\n",
    "    prediction_name, img_prediction = predict_model(img_batch, img_resized)\n",
    "    \n",
    "    filename = f\"webcam_{prediction_name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.jpg\"\n",
    "    path = '/Volumes/Datasets/SavedImages'\n",
    "    save_path = os.path.join(path, filename)\n",
    "    cv2.imwrite(save_path, img)\n",
    "\n",
    "    # Convert prediction image to base64 for display\n",
    "    chart_url = f\"{img_prediction}\"\n",
    "\n",
    "    return {'chart_url': chart_url}  # Send back as a JSON response\n",
    "\n",
    "\n",
    "# Run the Flask app\n",
    "if __name__ == '__main__':\n",
    "    threading.Thread(target=app.run, kwargs={\"host\": \"0.0.0.0\", \"port\": 5001, \"use_reloader\": False}).start()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
