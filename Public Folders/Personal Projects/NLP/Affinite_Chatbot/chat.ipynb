{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2412e704-cf66-49a3-879b-2d8a95d9e8c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLTK data downloaded successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/princemarcelle/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/princemarcelle/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries for the chatbot interface\n",
    "import random  # For randomly selecting responses from available options\n",
    "import json  # For loading the intents.json file with responses\n",
    "import torch  # PyTorch library for loading the trained model\n",
    "from model import NeuralNet  # Import our custom neural network class\n",
    "from preprocessing import bag_of_words, tokenize  # Import text processing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8785ddb-9aaa-4c2a-b626-e9f2e2910bfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNet(\n",
       "  (l1): Linear(in_features=114, out_features=8, bias=True)\n",
       "  (l2): Linear(in_features=8, out_features=8, bias=True)\n",
       "  (l3): Linear(in_features=8, out_features=13, bias=True)\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up device for inference (GPU if available, otherwise CPU)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  # Check for GPU availability\n",
    "\n",
    "# Load the intents data containing responses for each intent category\n",
    "with open('intents.json', 'r') as f:  # Open the intents.json file\n",
    "    intents = json.load(f)  # Parse JSON content into Python dictionary\n",
    "\n",
    "# Load the saved model data from the training phase\n",
    "FILE = 'data.pth'  # Define the saved model file\n",
    "data = torch.load(FILE)  # Load the saved data dictionary\n",
    "\n",
    "# Extract model parameters and training data from saved file\n",
    "input_size = data['input_size']  # Get the input layer size (vocabulary size)\n",
    "hidden_size = data['hidden_size']  # Get the hidden layer size\n",
    "output_size = data['output_size']  # Get the output layer size (number of intent categories)\n",
    "all_words = data['all_word']  # Get the vocabulary (all unique words)\n",
    "tags = data['tags']  # Get the list of intent tags\n",
    "model_state = data['model_state']  # Get the trained model weights and biases\n",
    "\n",
    "# Recreate the neural network model with the same architecture\n",
    "model = NeuralNet(input_size, hidden_size, output_size).to(device)  # Create model and move to device\n",
    "model.load_state_dict(model_state)  # Load the trained weights into the model\n",
    "model.eval()  # Set model to evaluation mode (no training, only inference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851535ae-7054-40f1-83f2-a8757943e1ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "let's chat! Type quit to exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you:  hey\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sam: Hello! Ready to connect with your family?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you:  what price should i get\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sam: We believe family connection should be accessible! Our subscription plans include free features for basic family networking and premium options for advanced features. Check our pricing page for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you:  how can i connect with my family members\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sam: I do not understand...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you:  how do i create an account\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sam: You can create family events easily! Go to the Events section, click 'Create Event', add details like date, time, location, and description. Family members can RSVP and you'll get real-time updates.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you:  bye\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sam: Take care! Your family is always here waiting for you.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you:  quit\n"
     ]
    }
   ],
   "source": [
    "# Set up the chatbot interface\n",
    "bot_name = \"Sam\"  # Define the chatbot's name\n",
    "print(\"let's chat! Type quit to exit\")  # Display welcome message and instructions\n",
    "\n",
    "# Main chat loop - continues until user types \"quit\"\n",
    "while True:\n",
    "    sentence = input(\"you: \")  # Get user input\n",
    "    if sentence == \"quit\":  # Check if user wants to exit\n",
    "        break  # Exit the chat loop\n",
    "\n",
    "    # Process the user's input for prediction\n",
    "    sentence = tokenize(sentence)  # Split the sentence into individual words/tokens\n",
    "    X = bag_of_words(sentence, all_words)  # Convert sentence to bag-of-words vector\n",
    "    X = X.reshape(1, X.shape[0])  # Reshape for batch processing (add batch dimension)\n",
    "    X = torch.from_numpy(X)  # Convert numpy array to PyTorch tensor\n",
    "\n",
    "    # Get prediction from the neural network\n",
    "    output = model(X)  # Forward pass through the model\n",
    "    _, predicted = torch.max(output, dim=1)  # Get the index of the highest probability class\n",
    "    tag = tags[predicted.item()]  # Convert index back to intent tag name\n",
    "\n",
    "    # Calculate confidence score for the prediction\n",
    "    probs = torch.softmax(output, dim=1)  # Convert raw outputs to probabilities\n",
    "    prob = probs[0][predicted.item()]  # Get the probability of the predicted class\n",
    "\n",
    "    # Respond based on confidence level\n",
    "    if prob.item() > 0.75:  # If confidence is above 75%\n",
    "        # Find the matching intent and select a random response\n",
    "        for intent in intents['intents']:  # Loop through all intents\n",
    "            if tag == intent['tag']:  # Find the matching intent category\n",
    "                print(f'{bot_name}: {random.choice(intent['responses'])}')  # Print random response\n",
    "    else:\n",
    "        # If confidence is too low, indicate lack of understanding\n",
    "        print(f'{bot_name}: I do not understand...')  # Print fallback response\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2129eac7-cc75-46dc-9b01-4125f9d9d5df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
